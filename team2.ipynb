{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(120000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 120 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 120\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\admin\\\\thapovan\\\\Thapovan2\\\\Config.cfg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xlrd\n",
    "import numpy as np\n",
    "import openpyxl as opx\n",
    "import glob\n",
    "import sys\n",
    "import datetime\n",
    "import xlwings as xl\n",
    "import copy\n",
    "from openpyxl.utils import range_boundaries\n",
    "from fuzzywuzzy import fuzz\n",
    "import pyodbc\n",
    "import math as math\n",
    "path = 'C:\\\\trial'\n",
    "ticker_list =[] \n",
    "folder = glob.glob(path + '\\\\*')\n",
    "company = [1]\n",
    "import ast\n",
    "c = 0\n",
    "import configparser\n",
    "con=configparser.ConfigParser()\n",
    "con.read(\"C:\\\\Users\\\\admin\\\\thapovan\\\\Thapovan2\\\\Config.cfg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "from nltk import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "lem = WordNetLemmatizer()\n",
    "stem = PorterStemmer()\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "new_words = [\"using\", \"show\", \"result\", \"large\", \"also\", \"iv\", \"one\", \"two\", \"new\", \"previously\", \"shown\"]\n",
    "stop_words = stop_words.union(new_words)\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\admin\\\\thapovan\\\\Thapovan2\\\\Corpus\")\n",
    "corpus_list = glob.glob(\"C:\\\\Users\\\\admin\\\\thapovan\\\\Thapovan2\\\\Corpus\\*csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_run(func):\n",
    "\n",
    "    def func_wrapper(*args, **kwargs):\n",
    "\n",
    "        try:\n",
    "           return func(*args, **kwargs)\n",
    "\n",
    "        except Exception as e:\n",
    "            server = ast.literal_eval(con.get(\"Setting\",\"server\"))\n",
    "            database = ast.literal_eval(con.get(\"Setting\",\"database\"))\n",
    "            username = ast.literal_eval(con.get(\"Setting\",\"username\"))\n",
    "            password = ast.literal_eval(con.get(\"Setting\",\"password\"))\n",
    "            cnxn = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "            cursor = cnxn.cursor()\n",
    "            return None\n",
    "\n",
    "    return func_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spinning_cursor():\n",
    "  #while True:\n",
    "    for cursor in '\\\\-/|':\n",
    "      time.sleep(0.3)\n",
    "      # Use '\\r' to move cursor back to line beginning\n",
    "      # Or use '\\b' to erase the last character\n",
    "      sys.stdout.write('\\r{}'.format(cursor))\n",
    "      # Force Python to write data into terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"values1.csv\", error_bad_lines=False)\n",
    "data = pd.read_csv(\"Thapovan_data.csv\", error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_match_list(db,trial):\n",
    "    p_list = []\n",
    "    for i in range(0,len(trial)):\n",
    "        metric = trial['trial'][i]\n",
    "        text = re.sub('[^a-zA-Z]', ' ', metric)\n",
    "    \n",
    "        #Convert to lowercase\n",
    "        text = text.lower()\n",
    "    \n",
    "        #remove tags\n",
    "        text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
    "    \n",
    "        # remove special characters and digits\n",
    "        text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "        ##Convert to list from string\n",
    "        text = text.split()\n",
    "    \n",
    "        ##Stemming\n",
    "        ps=PorterStemmer()\n",
    "        #Lemmatisation\n",
    "        lem = WordNetLemmatizer()\n",
    "        text = [lem.lemmatize(word) for word in text if not word in  \n",
    "            stop_words] \n",
    "        text = \" \".join(text)\n",
    "        tex_check = text.split(\" \")\n",
    "        list=[]\n",
    "        for key in data1[\"Keyword\"]:\n",
    "            count = 0\n",
    "            for j in tex_check:\n",
    "                if(j in key):\n",
    "                    count = count+1\n",
    "            list.append((count/len(tex_check))*100)  \n",
    "        l = []\n",
    "        count1 = 0 \n",
    "        maxi = max(list)\n",
    "        for val in list:\n",
    "            if(val==maxi):\n",
    "                l.append(count1)\n",
    "            count1 = count1+1 \n",
    "        l2=[]\n",
    "        for j in l:\n",
    "            l2.append(data['Term'][j])\n",
    "        p_list.append(l2)      \n",
    "    trial['possible'] = p_list\n",
    "    t_list = []\n",
    "    for i in range(0,len(db)):\n",
    "        metric = db['metric_name'][i]\n",
    "        text = re.sub('[^a-zA-Z]', ' ', metric)\n",
    "    \n",
    "        #Convert to lowercase\n",
    "        text = text.lower()\n",
    "    \n",
    "        #remove tags\n",
    "        text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
    "    \n",
    "        # remove special characters and digits\n",
    "        text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "        ##Convert to list from string\n",
    "        text = text.split()\n",
    "    \n",
    "        ##Stemming\n",
    "        ps=PorterStemmer()\n",
    "        #Lemmatisation\n",
    "        lem = WordNetLemmatizer()\n",
    "        text = [lem.lemmatize(word) for word in text if not word in  \n",
    "            stop_words] \n",
    "        text = \" \".join(text)\n",
    "        tex_check = text.split(\" \")\n",
    "        list=[]\n",
    "        for key in data1[\"Keyword\"]:\n",
    "            count = 0\n",
    "            for j in tex_check:\n",
    "                if(j in key):\n",
    "                    count = count+1\n",
    "            list.append((count/len(tex_check))*100)  \n",
    "        l = []\n",
    "        count1 = 0 \n",
    "        maxi = max(list)\n",
    "        for val in list:\n",
    "            if(val==maxi):\n",
    "                l.append(count1)\n",
    "            count1 = count1+1 \n",
    "        l2=[]\n",
    "        for j in l:\n",
    "            l2.append(data['Term'][j])\n",
    "        t_list.append(l2)    \n",
    "    db['possible'] = t_list    \n",
    "    final_list = []\n",
    "    fill = []\n",
    "    for i in range(0,len(trial)):\n",
    "        metric = trial['possible'][i]\n",
    "        final = []\n",
    "        for j in range(0,len(db)):\n",
    "            count = 0\n",
    "            for k in db['possible'][j]:\n",
    "                if(k in metric):\n",
    "                    count = count+1\n",
    "            final.append((count/len(db['possible'][j]))*100)\n",
    "            l3 =[]\n",
    "            for k in range(0,len(final)):\n",
    "                if(final[k]>0):\n",
    "                    l3.append(db['metric_name'][k])\n",
    "        if(len(l3)==len(final)):\n",
    "            final_list.append(fill)\n",
    "        else:    \n",
    "            final_list.append(l3) \n",
    "    return(final_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ticker_dictionary_build(tick):\n",
    "    #db_metrics = input(\"enter the name of the excel sheet with the database metrics for this particular ticker\")\n",
    "    #analyst_metrics = input(\"enter the name of the excel sheet with the analyst metrics for this particular ticker\")\n",
    "    print(\"Choose the name of the csv with the metrics from the database from the gven list. Enter the corresponding index number\")\n",
    "    for i in range(0,len(corpus_list)):\n",
    "        print(str(i) +')' + corpus_list[i])\n",
    "    db_metrics=corpus_list[int(input(\"Enter your choice:\"))]\n",
    "    print(\"Choose the name of the csv with the metrics from the analysts from the gven list. Enter the corresponding index number\")\n",
    "    for i in range(0,len(corpus_list)):\n",
    "        print(str(i) +')' + corpus_list[i])\n",
    "    analyst_metrics=corpus_list[int(input(\"Enter your choice:\"))]\n",
    "    db = pd.read_csv(db_metrics, error_bad_lines=False)\n",
    "    trial = pd.read_csv(analyst_metrics, error_bad_lines=False)\n",
    "    final_matches = return_match_list(db,trial)\n",
    "    trial['matches'] = final_matches\n",
    "    csv_name = tick + \"_matches.csv\"\n",
    "    trial.to_csv(csv_name)\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connection to database:\n",
    "server = ast.literal_eval(con.get(\"Setting\",\"server\"))\n",
    "database = ast.literal_eval(con.get(\"Setting\",\"database\"))\n",
    "username = ast.literal_eval(con.get(\"Setting\",\"username\"))\n",
    "password = ast.literal_eval(con.get(\"Setting\",\"password\"))\n",
    "cnxn = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = []\n",
    "#function which get information of file using its path and return 5 elements(year, month,date,ticker code,analyst name)\n",
    "def formating(filen):\n",
    "    data = filen.replace(path, '').split('\\\\')\n",
    "    del data[0]\n",
    "    del data[3]\n",
    "    if '-' in data[-1]:\n",
    "        temp = (data[-1].split('.')[0]).split('-')\n",
    "    elif '_' in data[-1]:\n",
    "        temp = (data[-1].split('.')[0]).split('_')\n",
    "    else:\n",
    "        temp = (data[-1].split('.')[0]).split(' ')\n",
    "    del data[-1]\n",
    "    data.append(temp[0])\n",
    "    data.append(temp[1])\n",
    "    print(data)\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#defined variable which help us to recognize year and quater of given column\n",
    "\n",
    "year_pattern_int=[]\n",
    "year_pattern_float=[]\n",
    "year_pattern_2di=[]\n",
    "quater_pattern=ast.literal_eval(con.get(\"Setting\",\"quater_pattern\"))\n",
    "bscf_names=ast.literal_eval(con.get(\"Setting\",\"bscf_names\"))\n",
    "#bscf_names=[\"balancesheet\",\"cashflows\",\"bs&cf\",\"cf&bs\",\"bsheet\",\"balancesheet&cashflow\",\"cashflow&balance sheet\",\"cash&balance\",\"adjustedbs\",\"annualbs&cf\",\"annualcf&bs\"]\n",
    "\n",
    "check_list = ast.literal_eval(con.get(\"Setting\",\"check_list\"))\n",
    "for i in range(2000,2031):\n",
    "    year_pattern_int.append(i)\n",
    "    year_pattern_float.append(float(i))\n",
    "    if i-2000<10:\n",
    "        year_pattern_2di.append('0'+str(i-2000))\n",
    "    else:\n",
    "        year_pattern_2di.append(str(i-2000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type of main function\n",
    "@safe_run\n",
    "def function1(excel_file,path_list):\n",
    "    #read excel file using openpyxl\n",
    "    wb=opx.load_workbook(excel_file,data_only=True)\n",
    "    print(\"Hi\")\n",
    "    sheet_tobechecked=wb.sheetnames #getting all the sheet name\n",
    "    nonhidden=[]\n",
    "    startrow={}\n",
    "    print(\"All the sheets prestent in the file are: \")\n",
    "    print(sheet_tobechecked)\n",
    "    #this part helps to ignore hidden sheets and to take related to BS , Cf and IS\n",
    "    names=[]\n",
    "    for i in range(0, len(sheet_tobechecked)):\n",
    "        curr_sheet = wb[sheet_tobechecked[i]]\n",
    "        if curr_sheet.sheet_state != 'hidden':\n",
    "            nonhidden.append(sheet_tobechecked[i])\n",
    "            if sheet_tobechecked[i].lower()=='bs' or sheet_tobechecked[i].lower()=='cf' or sheet_tobechecked[i].lower()=='model':\n",
    "                names.append(sheet_tobechecked[i])\n",
    "            else:\n",
    "                count_nobscf=1\n",
    "                for nam in bscf_names:\n",
    "                    if fuzz.partial_token_set_ratio(sheet_tobechecked[i].lower(),nam)>=80:\n",
    "                        names.append(sheet_tobechecked[i])\n",
    "    \n",
    "    sheet_tobechecked = names # all the sheet which are important to us\n",
    "    \n",
    "    #if no sheet found then return giving error as sheet_name_fault\n",
    "    if len(sheet_tobechecked)<=0:\n",
    "        return (2) # that means there is problem\n",
    "        '''print(nonhidden)\n",
    "        while True:\n",
    "            sheee=input(\"Enter the sheet name U want to process from above or for exit input'e' \")\n",
    "            if sheee!='e':\n",
    "                sheet_tobechecked.append(sheee)\n",
    "            else:\n",
    "                break'''\n",
    "    \n",
    "    sheet_tobechecked=list(set(sheet_tobechecked))# to remove repeated sheet names\n",
    "    print(\"Sheets to be checked: \")\n",
    "    print(sheet_tobechecked)\n",
    "    \n",
    "        \n",
    "    #defining variable\n",
    "    year_pre,quater_pre,q4_check_pre='','',0\n",
    "    \n",
    "    #unmerging all cells of every sheet of a file\n",
    "    for every_sheet in sheet_tobechecked:\n",
    "        \n",
    "        startrow_no=startingrow(wb,every_sheet)-1\n",
    "        if startrow_no<0:\n",
    "            startrow[every_sheet]=0\n",
    "        else:\n",
    "            startrow[every_sheet]=startrow_no\n",
    "        \n",
    "        curr_sheet=wb[every_sheet]\n",
    "        merge_list=copy.deepcopy(curr_sheet.merged_cells.ranges)\n",
    "        for group in merge_list :\n",
    "            split_arr = group.coord.split(':')\n",
    "            min_col, min_row, max_col, max_row = range_boundaries(group.coord)\n",
    "            top_left_cell_value = curr_sheet[split_arr[0]].value\n",
    "            curr_sheet.unmerge_cells(group.coord)\n",
    "            for row in curr_sheet.iter_rows(min_col=min_col, min_row=min_row, max_col=max_col, max_row=max_row):\n",
    "                for cell in row:\n",
    "                    cell.value = top_left_cell_value\n",
    "    wb.save(excel_file) #the modified file is been overwritten (have to look over it afterward by changing path)\n",
    "    #print(\"excel\")\n",
    "    #display(excel_file)\n",
    "    for sheetno in range(0,len(sheet_tobechecked)):\n",
    "        #print(sheet_tobechecked[sheetno])\n",
    "        address_dataframe=pd.DataFrame(columns=['q1','q2','q3','q4','tl','Ex']) # defining lookup table\n",
    "        excel_data = pd.read_excel(excel_file,sheet_name=sheet_tobechecked[sheetno],header=None,skiprows=[i for i in range(0,startrow[sheet_tobechecked[sheetno]])])\n",
    "        pd.options.display.max_columns = None\n",
    "        pd.options.display.max_rows=None\n",
    "        #print(\"This is excel data\")\n",
    "        #display(excel_data)\n",
    "        \n",
    "        #formating the dataframe by removing column and row having less than 10 element\n",
    "        excel_data=excel_data.replace(0,np.nan)\n",
    "        excel_data=excel_data.dropna(axis=0,thresh=10)\n",
    "        excel_data=excel_data.dropna(axis=1,thresh=10)\n",
    "        excel_data=excel_data.reset_index(drop=True)\n",
    "        if(len(excel_data.columns)==0):\n",
    "            continue # this line was added to handle exceptions in the code\n",
    "        excel_data.columns = range(excel_data.shape[1])\n",
    "        pd.options.display.max_columns = None\n",
    "        pd.options.display.max_rows=None\n",
    "        #display(excel_data)\n",
    "        startrowno=0\n",
    "        print(\"..........10%\")\n",
    "        #getting defination of each column\n",
    "        #print(len(excel_data.columns))\n",
    "        if len(excel_data.columns)>10: #changed from 10 to 3\n",
    "            temp_dataframe=excel_data[:10] # the first 10 element of a column will tell us about it \n",
    "            for j in temp_dataframe:\n",
    "                list_ele=list(temp_dataframe[j])\n",
    "                knowledge=[]\n",
    "                colno=j\n",
    "                for i in list_ele:\n",
    "                    #overlook element if its nan,none, or weeks or days written in it\n",
    "                    if str(i)=='nan' or str(i)=='None' or type(i)==datetime.datetime or \"week\" in str(i) or \"day\" in str(i):\n",
    "                        a=1\n",
    "                    #take only element which are keywords to us (like FY2017,3Q17 etc.) or else break which means any value have been occured\n",
    "                    elif (type(i)==float and i not in year_pattern_float) or (type(i)==int and i not in year_pattern_int):\n",
    "                        startrowno=list_ele.index(i)\n",
    "                        break\n",
    "                    else:\n",
    "                        knowledge.append(i)\n",
    "                \n",
    "                # proces further if the list taken for defining the row is not empty \n",
    "                if len(knowledge)>0:\n",
    "                    \n",
    "                    year_got,quater_got,q4_check_got=about_q_year(knowledge)\n",
    "                        \n",
    "                    #here is a small assumtion (if we got Q4 and all the elementused to define column is same we will take the curent row as Total of particuar year) )\n",
    "                    if q4_check_got==1 and year_got==year_pre and quater_got==quater_pre and q4_check_got==q4_check_pre:\n",
    "                        year_final=year_got\n",
    "                        quater_final='TL'\n",
    "                        q4_check_final=1\n",
    "                    else:\n",
    "                        # or else everything will be consider as it was given has been found about it\n",
    "                        year_pre=year_got\n",
    "                        quater_pre=quater_got\n",
    "                        q4_check_pre=q4_check_got\n",
    "                        year_final=year_got\n",
    "                        quater_final=quater_got\n",
    "                        q4_check_final=q4_check_got                       \n",
    "                    \n",
    "                    #if only year is written and nothing about the quater we take that as Total for particular year\n",
    "                    if year_got!='' and (quater_got=='' or quater_got=='TL' or quater_pre=='TL' or quater_pre==''):\n",
    "                        quater_final='TL'\n",
    "                    \n",
    "                    #printing and making dataframe(lookup table) of information of each columns\n",
    "                    if year_final!='' and quater_final!='':\n",
    "                        got_cor=1 #means we got something\n",
    "                        #print(knowledge,\"===\",end=\"\")\n",
    "                        #print(\"belongs to \"+\"20\"+year_final,\" \"+quater_final)\n",
    "                        if '1' in quater_final:\n",
    "                            qval='q1'\n",
    "                        elif '2' in quater_final:\n",
    "                            qval='q2'\n",
    "                        elif '3' in quater_final:\n",
    "                            qval='q3'\n",
    "                        elif '4' in quater_final:\n",
    "                            qval='q4'\n",
    "                        else:\n",
    "                            qval='tl'\n",
    "                        try:\n",
    "                            address_dataframe.loc[\"20\"+year_final][qval]=[startrowno,colno]\n",
    "                        except Exception:\n",
    "                            address_dataframe.loc[\"20\"+year_final]='Nan'\n",
    "                            address_dataframe.loc[\"20\"+year_final][qval]=[startrowno,colno]                           \n",
    "                 \n",
    "        #display(address_dataframe)\n",
    "        print(\"..........20%\")\n",
    "        #db_connect()\n",
    "        #extra fro shoeing rows which doesnot match\n",
    "        not_present=pd.DataFrame(columns=excel_data.columns)\n",
    "        coll=0\n",
    "        \n",
    "        #this is to make a list of year and its respective column number from lookup take which has to consider\n",
    "        row_name_year=list(address_dataframe.index)\n",
    "        row_name_year.sort()\n",
    "        if int(path_list[0])<int(row_name_year[-1]):\n",
    "            cur_yr=int(path_list[0])\n",
    "            count_yr=0\n",
    "            count = 0\n",
    "            metric_col=[]\n",
    "            par_year=[]\n",
    "            metric_row=20\n",
    "            year_tosearch=cur_yr\n",
    "            \n",
    "            lowest_year=min_year(\"'\"+path_list[3]+\"'\")\n",
    "\n",
    "            while (count_yr<6 and year_tosearch>=lowest_year):\n",
    "                year_tosearch=cur_yr-(count_yr+1)\n",
    "                val=address_dataframe['q1'][str(year_tosearch)]\n",
    "                if val!='Nan':\n",
    "                    if val[0]<metric_row:\n",
    "                        metric_row=val[0]\n",
    "                    metric_col.append(val[1])\n",
    "                    par_year.append(year_tosearch)\n",
    "                    count_yr+=1\n",
    "            print(\"Years considered:\")\n",
    "            print(par_year)\n",
    "            print(\"Columns used:\")\n",
    "            print(metric_col)\n",
    "            print(\"Start Row: \")\n",
    "            print(metric_row)\n",
    "            print(\"..........30%\")\n",
    "                \n",
    "\n",
    "            all_metric=set()\n",
    "            def_metrics = []\n",
    "            matched_metric = []\n",
    "            mid_matched =[]\n",
    "            maybe_metrics = []\n",
    "            no_metrics = []\n",
    "            if(type(excel_data.iloc[metric_row][0])==str):\n",
    "                c = 0\n",
    "            else:\n",
    "                c = 1\n",
    "            metric_list =[]    \n",
    "            list_subs_found =[]\n",
    "            for rowss in range(metric_row,excel_data.shape[0]):\n",
    "                metric_found=[]\n",
    "                s_var = ['Macau','Venetian']\n",
    "                list_metric_found=[]\n",
    "                com_met=set()\n",
    "                a_metric=str(excel_data.iloc[rowss][c])\n",
    "                flag_sub = 0\n",
    "                for i in s_var:\n",
    "                    if i in a_metric:\n",
    "                        s = i\n",
    "                        flag_sub = 1\n",
    "                if flag_sub==0:\n",
    "                    if rowss>metric_row+5:\n",
    "                        for i in range(1,5):\n",
    "                            for j in s_var:\n",
    "                                if j in str(excel_data.iloc[rowss-i][c]):\n",
    "                                    s=j\n",
    "                                    flag_sub =1\n",
    "                            if flag_sub==1:    \n",
    "                                    break\n",
    "                if flag_sub==0: \n",
    "                    s = \"Unknown\"\n",
    "                for met_num in range(0,6):\n",
    "                    #getting the metric name wrt the year,quater,ticker and value send\n",
    "                    metric,subs_list=get_metric_name(par_year[met_num],path_list[3],excel_data.iloc[rowss][metric_col[met_num]],a_metric)\n",
    "                    #remove this if it fucks up\n",
    "                    for i in range(0,len(metric)):\n",
    "                        metric[i] = metric[i] +\"[\"+str(subs_list[i])+\"]\"\n",
    "                    metric = set(metric)\n",
    "                    subs_list = set(subs_list)\n",
    "                    com_met.update(metric)\n",
    "                    metric_list.extend(metric)\n",
    "                    list_metric_found.extend(metric)\n",
    "                    list_subs_found.extend(subs_list)\n",
    "                if com_met:\n",
    "                    spinning_cursor()\n",
    "                    #print(com_met)\n",
    "                    #print(list_metric_found)\n",
    "                for un_met in com_met:\n",
    "                    #if min 60% of them says that yes the values are of  particlar metric we take it \n",
    "                    if list_metric_found.count(un_met)/6 >= 0.6:\n",
    "                        a = un_met +\"--->\"+a_metric+ \"--->\"+ str(rowss) +\"--->\"+ s\n",
    "                        metric_found.append(un_met)\n",
    "                        matched_metric.append(un_met)\n",
    "                        def_metrics.append(a)\n",
    "                    elif list_metric_found.count(un_met)/6 >= 0.4 and list_metric_found.count(un_met)/6 <0.6:\n",
    "                        if(un_met not in matched_metric): \n",
    "                            mid_matched.append(un_met)\n",
    "                            a = un_met +\"--->\"+a_metric+ \"--->\"+ str(rowss) +\"--->\"+ s\n",
    "                            maybe_metrics.append(a)\n",
    "                    elif list_metric_found.count(un_met)/6 < 0.4:\n",
    "                        if(un_met not in matched_metric and un_met not in mid_matched):\n",
    "                            no_metrics.append(un_met)\n",
    "                if metric_found:\n",
    "                    #print(rowss,metric_found)\n",
    "                    all_metric.update(metric_found)\n",
    "                else:\n",
    "                    not_present.loc[coll]=list(excel_data.loc[rowss])\n",
    "                    coll+=1\n",
    "                \n",
    "            #print(all_metric,len(all_metric))#printing all mertric found in database \n",
    "            print(\"..........90%\")\n",
    "            #metric_db=get_metriclist_from_db(path_list[0],path_list[3])\n",
    "            #print(\"metric not in actuals---\")\n",
    "            #print(list(set(metric_db)-set(all_metric)))# all metric we couldn't find wrt to a ticker\n",
    "            #print(\"metric not with respect to analyst\")\n",
    "            #print(list(set(get_metriclist_wrt_analyst(path_list[3],path_list[4]))-set(all_metric)))#metric which we couldn't finf wrt to analyst\n",
    "            # the percentge accuracy will be calculate wby no of metric_found by us divided by total number of metric wrt analyst \n",
    "            #print()\n",
    "            #print()\n",
    "            #print(\"ACCURACY==\")\n",
    "            #all_metric = list(all_metric)\n",
    "            #print(\"Number of total element in Actual DB=\", len(metric_db))\n",
    "            #print(\"Number of metric found by us=\",len(all_metric))\n",
    "            #for i in range(0,len(all_metric)):\n",
    "            #    all_metric[i] = all_metric[i].replace(all_metric[i][all_metric[i].find(\"[\")+1:all_metric[i].find(\"]\")],\"\").strip(\"][\")\n",
    "            #print(\"accuracy wrt to Actual=\",len(list(set(metric_db)&set(all_metric)))*100/len(metric_db))\n",
    "            #print()\n",
    "            #print(\"Number of total element in Estimated DB wrt Analyst=\", len(get_metriclist_wrt_analyst(path_list[3],path_list[4])))\n",
    "            #z=set(get_metriclist_wrt_analyst(path_list[3],path_list[4]))\n",
    "            #print(\"Number of metric found by us=\",len(z&set(all_metric)))\n",
    "            #print(\"Accuracy with respect to estimates=\",len(z&set(all_metric))*100/len(z))\n",
    "            print(\"list of definate metrics \\n\", list(set(def_metrics)))\n",
    "            print()\n",
    "            print(\"list of semi-definate metrics \\n\", list(set(maybe_metrics)))\n",
    "            print()\n",
    "            print(\"list of Unmatched metrics \\n\", list(set(no_metrics)))\n",
    "            m_metrics = list(set(maybe_metrics))\n",
    "            d_metrics = list(set(def_metrics))\n",
    "            print()\n",
    "            print(\"The partially matched metrics can be mapped as so\")\n",
    "            print()\n",
    "            for metric in m_metrics:\n",
    "                poss = []\n",
    "                poss = metric.split(\"--->\")\n",
    "                col=[c]\n",
    "                for i in range(0,6):\n",
    "                    col.append(metric_col[i])\n",
    "                temp_metric = pd.DataFrame()\n",
    "                temp_metric=temp_metric.append(excel_data.loc[[int(poss[2])],col[0:7]])\n",
    "                temp_metric.rename(columns={col[0]:'Name',col[1]:str(par_year[0])+'Q1',col[2]:str(par_year[1])+'Q1',col[3]:str(par_year[2])+'Q1',col[4]:str(par_year[3])+'Q1',col[5]:str(par_year[4])+'Q1',col[6]:str(par_year[5])+'Q1'},inplace=True)\n",
    "                yr = str(par_year[0:6]).strip('][').replace(\" ,\",\"\")\n",
    "                #display(temp_metric)\n",
    "                sub = int(poss[0][poss[0].find(\"[\")+1:poss[0].find(\"]\")])\n",
    "                poss0 = poss[0].replace(poss[0][poss[0].find(\"[\")+1:poss[0].find(\"]\")],\"\").strip(\"][\")\n",
    "                select_stmt1 = F\"select value from dbo.cc_actual_metrics_consolidated where \" \\\n",
    "                    F\"metric_name='{poss0}' and subsidiary_id ={sub} and quarter = 'Q1' and ticker_code ='{path_list[3]}' and financial_year in (select convert(int,id) from [adm_fnSplitter]('{yr}')) order by financial_year\"  \n",
    "                cursor.execute(select_stmt1)\n",
    "                row = cursor.fetchone()\n",
    "                m_l =[]\n",
    "                m_l1 = [poss0]\n",
    "                while row:\n",
    "                    m_l.append(str(row.value))\n",
    "                    row= cursor.fetchone()\n",
    "                m_l.reverse()\n",
    "                m_l1.extend(m_l)\n",
    "                temp_metric = temp_metric.append(pd.Series(m_l1, index=['Name',str(par_year[0])+'Q1',str(par_year[1])+'Q1',str(par_year[2])+'Q1',str(par_year[3])+'Q1',str(par_year[4])+'Q1',str(par_year[5])+'Q1']), ignore_index=True) \n",
    "                types = [\"Analyst metric\",\"Database metric\"]\n",
    "                temp_metric['Type'] = types\n",
    "                #temp_metric=temp_metric.set_index('Type')\n",
    "                display(temp_metric)\n",
    "                #print(m_l)  \n",
    "                #print(f\"{'DB metric name and subsidiary id =':<30}{poss[0]:>15}\",\n",
    "                      #f\"\\n{'Analyst metric name =':<30}{poss[1]:>15}\",\n",
    "                      #f\"\\n{'Row Number in excel =':<30}{poss[2]:>15}\",\n",
    "                      #f\"\\n{'Row Number in excel =':<30}{poss[3]:>15}\")\n",
    "                print(\"DB metric name and subsidiary id: \\n\" + poss[0])\n",
    "                print(\"Analyst metric name: \\n\" + poss[1])\n",
    "                print(\"Row Number in excel: \\n\" + poss[2])\n",
    "                print(\"Subsidiary Name from Analyst: \\n\" + poss[3])\n",
    "                ip = input(\"enter [Y]es if you think this is a valid match and [N]o if you think it can be bypassed\")\n",
    "                if(ip is \"Y\"):\n",
    "                    def_metrics.append(metric)\n",
    "                else:\n",
    "                    continue\n",
    "            #matched_df = pd.DataFrame()\n",
    "            print(\"the def matched metrics are\")\n",
    "            for m in d_metrics:\n",
    "                poss = []\n",
    "                poss = m.split(\"--->\")\n",
    "                col=[c]\n",
    "                an_metric = pd.DataFrame(columns = ['Name',str(par_year[0])+'Q1',str(par_year[1])+'Q1',str(par_year[2])+'Q1',str(par_year[3])+'Q1',str(par_year[4])+'Q1',str(par_year[5])+'Q1'])\n",
    "                temp_metric = pd.DataFrame()\n",
    "                columns = ['Name',str(par_year[0])+'Q1',str(par_year[1])+'Q1',str(par_year[2])+'Q1',str(par_year[3])+'Q1',str(par_year[4])+'Q1',str(par_year[5])+'Q1']\n",
    "                for i in range(0,6):\n",
    "                    col.append(metric_col[i])\n",
    "                temp_metric=temp_metric.append(excel_data.loc[[int(poss[2])],col[0:7]])\n",
    "                temp_metric.rename(columns={col[0]:'Name',col[1]:str(par_year[0])+'Q1',col[2]:str(par_year[1])+'Q1',col[3]:str(par_year[2])+'Q1',col[4]:str(par_year[3])+'Q1',col[5]:str(par_year[4])+'Q1',col[6]:str(par_year[5])+'Q1'},inplace=True)\n",
    "                #display(temp_metric)  \n",
    "                inx = metric_list.index(poss[0])\n",
    "                sub = int(poss[0][poss[0].find(\"[\")+1:poss[0].find(\"]\")])\n",
    "                poss0 = poss[0].replace(poss[0][poss[0].find(\"[\")+1:poss[0].find(\"]\")],\"\").strip(\"][\")\n",
    "                #print(sub)\n",
    "                if sub is not None and sub is not \"None\":    \n",
    "                    select_stmt1 = F\"select value from dbo.cc_actual_metrics_consolidated where \" \\\n",
    "                        F\"metric_name = '{poss0}' and subsidiary_id = {sub} and ticker_code = '{path_list[3]}' and quarter = 'Q1' and financial_year in (select convert(int,id) from [adm_fnSplitter]('2012,2013,2014,2015,2016,2017')) order by financial_year\"\n",
    "                else:\n",
    "                    select_stmt1 = F\"select value from dbo.cc_actual_metrics_consolidated where \" \\\n",
    "                        F\"metric_name = '{poss0}' and ticker_code = '{path_list[3]}' and quarter = 'Q1' and financial_year in (select convert(int,id) from [adm_fnSplitter]('2012,2013,2014,2015,2016,2017')) order by financial_year\"\n",
    "                cursor.execute(select_stmt1)\n",
    "                row = cursor.fetchone()\n",
    "                m_l =[]\n",
    "                m_l1 = [poss0]\n",
    "                while row:\n",
    "                    m_l.append(str(row.value))\n",
    "                    row= cursor.fetchone()\n",
    "                m_l.reverse()\n",
    "                m_l1.extend(m_l)\n",
    "                temp_metric = temp_metric.append(pd.Series(m_l1, index=['Name',str(par_year[0])+'Q1',str(par_year[1])+'Q1',str(par_year[2])+'Q1',str(par_year[3])+'Q1',str(par_year[4])+'Q1',str(par_year[5])+'Q1']), ignore_index=True) \n",
    "                types = [\"Analyst metric\",\"Database metric\"]\n",
    "                temp_metric['Type'] = types\n",
    "                #temp_metric=temp_metric.set_index('Type')\n",
    "                display(temp_metric)\n",
    "                #print(m_l)\n",
    "                #print(f\"{'DB metric name and subsidiary id =':<30}{poss[0]:>15}\",\n",
    "                      #f\"\\n{'Analyst metric name =':<30}{poss[1]:>15}\",\n",
    "                      #f\"\\n{'Row Number in excel =':<30}{poss[2]:>15}\",\n",
    "                      #f\"\\n{'Row Number in excel =':<30}{poss[3]:>15}\")\n",
    "                print(\"DB metric name and subsidiary id: \\n\" + poss[0])\n",
    "                print(\"Analyst metric name: \\n\" + poss[1])\n",
    "                print(\"Row Number in excel: \\n\" + poss[2])\n",
    "                print(\"Subsidiary Name from Analyst: \\n\" + poss[3])\n",
    "                #matched_df = matched_df.append(excel_data.loc[[int(poss[2])],col[0:7]], ignore_index = True)\n",
    "            print()\n",
    "            #print(\"The definately matched metrics are\")\n",
    "            print()\n",
    "            #display(matched_df)\n",
    "            #print(\"The matches made are\")\n",
    "            #for m in def_metrics:\n",
    "            #   print(m)\n",
    "            #display(not_present)\n",
    "    \n",
    "    print(\"The list of matches to be thrown into the database are: \")\n",
    "    cnt =0\n",
    "    l = []\n",
    "    for i in def_metrics:\n",
    "        p = []\n",
    "        p = i.split(\"--->\")\n",
    "        l.append(p)\n",
    "    final_db = pd.DataFrame(l,columns =['Database_metric','Analyst_metric','Row Number','Subsidiary Name'])\n",
    "    #display(final_db)\n",
    "    final_flag ='N'\n",
    "    while final_flag is not 'Y':\n",
    "        display(final_db)\n",
    "        inp = input(\"If you are happy with these values to be thrown into the database, type [Y]. If not, type the row numbers seperated by a comma (,)\\n\")\n",
    "        if inp is 'Y':\n",
    "            final_flag = 'Y'\n",
    "            continue\n",
    "        else:\n",
    "            fin =[]\n",
    "            fin = inp.split(\",\")\n",
    "        for i in range(0,len(fin)):\n",
    "            fin[i] = int(fin[i])\n",
    "        final_db = final_db.drop(fin,axis = 0)    \n",
    "    if got_cor:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "   \n",
    "    '''qw=input()\n",
    "            if qw=='q':\n",
    "                sys.exit()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@safe_run\n",
    "#get the minimum year present in dtabase for given ticker\n",
    "def min_year(ticker):\n",
    "    select_stmt1 = F\" select distinct financial_year from dbo.cc_actual_metrics_consolidated where ticker_code={ticker} order by financial_year\"\n",
    "    cursor.execute(select_stmt1)\n",
    "    row = cursor.fetchone()\n",
    "    res_array = []\n",
    "    while row:\n",
    "        res_array.append(row[0])\n",
    "        row = cursor.fetchone()\n",
    "    #print(\"Minimum year present in the data base for the given ticker: \")    \n",
    "    #print(res_array[0])\n",
    "    return(res_array[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@safe_run\n",
    "def get_metric_name (year,ticker,value,a_metric,quarter='Q1'):\n",
    "    flag = 0\n",
    "    flag_not_found = 1\n",
    "    possible_list = \"\"\n",
    "    try:\n",
    "        index = ticker_dictionary[ticker_dictionary['trial']==a_metric].index.item()\n",
    "        possible_list = ticker_dictionary['matches'][index]\n",
    "        param = possible_list.strip(\"][\").replace(\"'\",\"\").replace(\", \",\",\").replace(\" ,\",\",\")\n",
    "        flag = 1\n",
    "    except:\n",
    "        pass\n",
    "    #Also write a conditional if statement for the case of an empty list \n",
    "    ticker_code = \"'\"+ticker+\"'\"\n",
    "    year = year\n",
    "    quarter = \"'\"+quarter+\"'\"\n",
    "    if type(value)==int or (type(value)==float and str(value)!='nan'):\n",
    "        if abs(value)>=1:\n",
    "            #when value is greater than 1\n",
    "            valueo= \"'\"+str(value)+\"'\" #orginal value\n",
    "            value1 = \"'\"+str(int(value))+\".%\"+\"'\" # integered value\n",
    "            value2 = \"'\"+str(round(value, 2))+\"%\"+\"'\" #value when rounded upto 2\n",
    "            value3 = \"'\"+str(-1*int(value))+\".%\"+\"'\" #integered with negation\n",
    "            value4 = \"'\"+str(-1*round(value,2))+\"%\"+\"'\" # round upto 2 with negation\n",
    "            #print(valueo,value1,value2,value3,value4)\n",
    "            if(len(possible_list)>2 and flag==1):\n",
    "                select_stmt1 = F\"select distinct metric_name, subsidiary_id from dbo.cc_actual_metrics_consolidated where \" \\\n",
    "                    F\"metric_name in (select id from [adm_fnSplitter]('{param}')) and \" \\\n",
    "                    F\"ticker_code={ticker_code} and financial_year = {year} and quarter = {quarter} and \" \\\n",
    "                    F\"(value like {valueo} or value like {value1} or value like {value2} or value like {value3} or value like {value4})\"   \n",
    "            else:\n",
    "                select_stmt1 = F\"select distinct metric_name, subsidiary_id from dbo.cc_actual_metrics_consolidated where \" \\\n",
    "                    F\"ticker_code={ticker_code} and financial_year = {year} and quarter = {quarter} and \" \\\n",
    "                    F\"(value like {valueo} or value like {value1} or value like {value2} or value like {value3} or value like {value4})\"\n",
    "            subs_list = []    \n",
    "            metric_list=[]\n",
    "            cursor.execute(select_stmt1)\n",
    "            row = cursor.fetchone()\n",
    "            while row:\n",
    "                flag_not_found = 0\n",
    "                metric_list.append(row.metric_name)\n",
    "                subs_list.append(row.subsidiary_id)\n",
    "                row = cursor.fetchone()\n",
    "        else:\n",
    "            #if value less than 1\n",
    "            valueo= \"'\"+str(value*100)+\"'\" #orginal with 100 multiplied\n",
    "            value1 = \"'\"+str(int(value*100))+\".%\"+\"'\" # multiply by 100 and then integered\n",
    "            value3 = \"'\"+str(-1*int(value*100))+\".%\"+\"'\" # multiply by 100 and integer and negate it\n",
    "            #print(\"with 100\",valueo,value1,value3)\n",
    "            if(len(possible_list)>2 and flag==1):\n",
    "                select_stmt1 = F\"select distinct metric_name, subsidiary_id from dbo.cc_actual_metrics_consolidated where \" \\\n",
    "                    F\"metric_name in (select id from [adm_fnSplitter]('{param}')) and \" \\\n",
    "                    F\"ticker_code={ticker_code} and financial_year = {year} and quarter = {quarter} and \" \\\n",
    "                    F\"(value like {valueo} or value like {value1} or value like {value3})\"\n",
    "            else:\n",
    "                select_stmt1 = F\"select distinct metric_name, subsidiary_id from dbo.cc_actual_metrics_consolidated where \" \\\n",
    "                    F\"ticker_code={ticker_code} and financial_year = {year} and quarter = {quarter} and \" \\\n",
    "                    F\"(value like {valueo} or value like {value1} or value like {value3})\"\n",
    "            subs_list = []    \n",
    "            metric_list=[]\n",
    "            cursor.execute(select_stmt1)\n",
    "            row = cursor.fetchone()\n",
    "            flag_got_with_100=0\n",
    "            while row:\n",
    "                metric_list.append(row.metric_name)\n",
    "                subs_list.append(row.subsidiary_id)\n",
    "                row = cursor.fetchone()\n",
    "                flag_got_with_100=1\n",
    "\n",
    "            #if not flag_got_with_100:\n",
    "            valueo = \"'\"+str(value)+\"'\" #orginal value\n",
    "            value1 = \"'\"+str(round(value,2))+\"%\"+\"'\" # round upto 2\n",
    "            value3 = \"'\"+str(-1*round(value,2))+\"%\"+\"'\" # round upto 2  and negate it\n",
    "            #print(\"without 100\",valueo,value1,value3)\n",
    "            if(len(possible_list)>2 and flag==1):\n",
    "                select_stmt1 = F\"select distinct metric_name, subsidiary_id from dbo.cc_actual_metrics_consolidated where \" \\\n",
    "                    F\"metric_name in (select id from [adm_fnSplitter]('{param}')) and \" \\\n",
    "                    F\"ticker_code={ticker_code} and financial_year = {year} and quarter = {quarter} and \" \\\n",
    "                    F\"(value like {valueo} or value like {value1} or value like {value3})\"\n",
    "            else:\n",
    "                select_stmt1 = F\"select distinct metric_name, subsidiary_id from dbo.cc_actual_metrics_consolidated where \" \\\n",
    "                    F\"ticker_code={ticker_code} and financial_year = {year} and quarter = {quarter} and \" \\\n",
    "                    F\"(value like {valueo} or value like {value1} or value like {value3})\"\n",
    "            cursor.execute(select_stmt1)\n",
    "            row = cursor.fetchone()\n",
    "            while row:\n",
    "                #to_confirm\n",
    "                metric_list.append(row.metric_name)\n",
    "                subs_list.append(row.subsidiary_id)\n",
    "                row = cursor.fetchone()\n",
    "                flag_not_found = 0\n",
    "        if(flag_not_found == 1 and flag == 1):\n",
    "            if abs(value)>=1:\n",
    "                #when value is greater than 1\n",
    "                valueo= \"'\"+str(value)+\"'\" #orginal value\n",
    "                value1 = \"'\"+str(int(value))+\".%\"+\"'\" # integered value\n",
    "                value2 = \"'\"+str(round(value, 2))+\"%\"+\"'\" #value when rounded upto 2\n",
    "                value3 = \"'\"+str(-1*int(value))+\".%\"+\"'\" #integered with negation\n",
    "                value4 = \"'\"+str(-1*round(value,2))+\"%\"+\"'\" # round upto 2 with negation\n",
    "                select_stmt1 = F\"select distinct metric_name, subsidiary_id from dbo.cc_actual_metrics_consolidated where \" \\\n",
    "                    F\"metric_name not in (select id from [adm_fnSplitter]('{param}')) and \" \\\n",
    "                    F\"ticker_code={ticker_code} and financial_year = {year} and quarter = {quarter} and \" \\\n",
    "                    F\"(value like {valueo} or value like {value1} or value like {value2} or value like {value3} or value like {value4})\"\n",
    "                metric_list=[]\n",
    "                subs_list = []\n",
    "                cursor.execute(select_stmt1)\n",
    "                row = cursor.fetchone()\n",
    "                while row:\n",
    "                    metric_list.append(row.metric_name)\n",
    "                    subs_list.append(row.subsidiary_id)\n",
    "                    row = cursor.fetchone()\n",
    "            else:\n",
    "                #if value less than 1\n",
    "                valueo= \"'\"+str(value*100)+\"'\" #orginal with 100 multiplied\n",
    "                value1 = \"'\"+str(int(value*100))+\".%\"+\"'\" # multiply by 100 and then integered\n",
    "                value3 = \"'\"+str(-1*int(value*100))+\".%\"+\"'\" # multiply by 100 and integer and negate it  \n",
    "                select_stmt1 = F\"select distinct metric_name, subsidiary_id from dbo.cc_actual_metrics_consolidated where \" \\\n",
    "                    F\"metric_name not in (select id from [adm_fnSplitter]('{param}')) and \" \\\n",
    "                    F\"ticker_code={ticker_code} and financial_year = {year} and quarter = {quarter} and \" \\\n",
    "                    F\"(value like {valueo} or value like {value1} or value like {value3})\"\n",
    "                metric_list=[]\n",
    "                subs_list = []\n",
    "                cursor.execute(select_stmt1)\n",
    "                row = cursor.fetchone()\n",
    "                flag_got_with_100=0\n",
    "                while row:\n",
    "                    metric_list.append(row.metric_name)\n",
    "                    subs_list.append(row.subsidiary_id)\n",
    "                    row = cursor.fetchone()\n",
    "                    flag_got_with_100=1\n",
    "                valueo = \"'\"+str(value)+\"'\" #orginal value\n",
    "                value1 = \"'\"+str(round(value,2))+\"%\"+\"'\" # round upto 2\n",
    "                value3 = \"'\"+str(-1*round(value,2))+\"%\"+\"'\" # round upto 2  and negate it\n",
    "                select_stmt1 = F\"select distinct metric_name, subsidiary_id from dbo.cc_actual_metrics_consolidated where \" \\\n",
    "                    F\"metric_name not in (select id from [adm_fnSplitter]('{param}')) and \" \\\n",
    "                    F\"ticker_code={ticker_code} and financial_year = {year} and quarter = {quarter} and \" \\\n",
    "                    F\"(value like {valueo} or value like {value1} or value like {value3})\"   \n",
    "                cursor.execute(select_stmt1)\n",
    "                row = cursor.fetchone()\n",
    "                while row:\n",
    "                    #to_confirm\n",
    "                    metric_list.append(row.metric_name)\n",
    "                    subs_list.append(row.subsidiary_id)\n",
    "                    row = cursor.fetchone()\n",
    "        return(metric_list,subs_list)\n",
    "    else:\n",
    "        return([],[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which tells about the quater and year the particular column belongs to\n",
    "def about_q_year(checkar):\n",
    "    \n",
    "    checkar_duplicate=np.copy(checkar)\n",
    "    quater=''\n",
    "    year=''\n",
    "    year_flag=0\n",
    "    quater_flag=0\n",
    "    q4_check=0\n",
    "    checkar=[]\n",
    "    datetime_flag=1\n",
    "    for i_che in checkar_duplicate:\n",
    "        checkar.append(str(i_che))\n",
    "    \n",
    "    for i_che in range(0,len(checkar)):\n",
    "        \n",
    "        if not year_flag:\n",
    "            #checking if year is presenr in (2017,2016 format)\n",
    "            for j_y in year_pattern_int:\n",
    "                if str(j_y) in checkar[i_che]:\n",
    "                    year=str(j_y)[2:]\n",
    "                    checkar[i_che]=checkar[i_che].replace(str(j_y),'')\n",
    "                    checkar[i_che]=checkar[i_che].replace(year,'')\n",
    "                    year_flag=1\n",
    "                    break\n",
    "        if not year_flag:\n",
    "            #checking if the year is present in 2 digited format like 17,16)\n",
    "            for j_y in year_pattern_2di:\n",
    "                if str(j_y) in checkar[i_che]:\n",
    "                    year=str(j_y)\n",
    "                    checkar[i_che]=checkar[i_che].replace(year,'')\n",
    "                    year_flag=1\n",
    "                    break\n",
    "\n",
    "        if not quater_flag:\n",
    "            # getting info about the quater\n",
    "            for i_p in quater_pattern:\n",
    "                checkar[i_che]=checkar[i_che].replace(year,'')\n",
    "                checkar[i_che]=checkar[i_che].replace(\"20\"+year,'')\n",
    "                if i_p in checkar[i_che].lower():\n",
    "                    quater=i_p\n",
    "                    quater_flag=1\n",
    "                    break       \n",
    "        \n",
    "        if year_flag and quater_flag:\n",
    "            break\n",
    "    #returning the year and quater and if its 4th quatered or not\n",
    "    return(year,quater,q4_check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funtion to avoid te rough work present in top and retutn the row no from which its important\n",
    "def startingrow(wb,sheet_name):\n",
    "    curr_sheet = wb[sheet_name]\n",
    "    flag = 0\n",
    "    row = 0\n",
    "    for col in curr_sheet.iter_cols(max_col=20,max_row=15):\n",
    "        for cell in col:\n",
    "            if cell.value is not None:\n",
    "                for data in check_list:\n",
    "                    if fuzz.partial_ratio(str(data),str(cell.value)) == 100:\n",
    "                        row = cell.row\n",
    "                        flag =1\n",
    "                        break\n",
    "                if flag == 1:\n",
    "                    break\n",
    "        if flag == 1:\n",
    "            break\n",
    "\n",
    "    #print(row)\n",
    "    return(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which return all the metric anme with repect to ticker in actuals\n",
    "@safe_run\n",
    "def get_metriclist_from_db(year, ticker):\n",
    "\n",
    "    ticker_code = \"'\"+ticker+\"'\"\n",
    "    year = year\n",
    "    select_stmt1 = F\"select distinct metric_name from dbo.cc_actual_metrics_consolidated where ticker_code = {ticker_code} \" \\\n",
    "        F\" and financial_year = {year}\"\n",
    "\n",
    "    cursor.execute(select_stmt1)\n",
    "    row = cursor.fetchone()\n",
    "    metric_list_comp = []\n",
    "    while row:\n",
    "        metric_list_comp.append(row[0])\n",
    "        row = cursor.fetchone()\n",
    "\n",
    "    return (metric_list_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which return aall the metric name wrt to analyst from estimated database\n",
    "@safe_run\n",
    "def get_metriclist_wrt_analyst(ticker,analyst):\n",
    "    ticker_code = \"'\"+ticker+\"'\"\n",
    "    analyst_name=\"'%\"+analyst+\"%'\"\n",
    "    select_stmt1 = F\" select distinct metric_name from [dbo].[cc_metrics_consolidated] where ticker_code = {ticker_code} and quarter='q1' and analyst_name like {analyst_name} order by metric_name\"\n",
    "    cursor.execute(select_stmt1)\n",
    "    row = cursor.fetchone()\n",
    "    res_array = []\n",
    "    while row:\n",
    "        res_array.append(row[0])\n",
    "        row = cursor.fetchone()\n",
    "    return(res_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\trial\\2018\\may\\2 MAY\\lvs\\LVS-Thomas Allen.xlsx\n",
      "['2018', 'may', '2 MAY', 'LVS', 'Thomas Allen']\n",
      "The current ticker that is detected is  LVS\n",
      "Would you like to proceed with this ticker? [Y]//[N] Y\n",
      "The dictionary has already been built\n",
      "Hi\n",
      "All the sheets prestent in the file are: \n",
      "['ImportantDisclosures', 'LVS', 'Tables 4', 'EBITDA Val', 'MacauSum', 'Tables 3', 'Sensitivity', 'Bull-Bear', 'DCF Val', 'Tables 2', 'Tables-Parisian', 'CompSheet - Output', 'Implied val', 'ROIC', '3Q15', '2Q15', '1Q15', '4Q14', '3Q14', '2Q14', '1Q14', '4Q13', '3Q13', '2Q13', '1Q13', 'Sheet1', 'Macro1', 'Sites5-6', 'Analyst Day', 'Sands China', 'Sing Market', 'Sing Tables', 'MW-Cache', 'Tables', 'Metrics', 'Macau act v est', 'Sing Sensitivity', 'Props', 'Prop Sum', 'Debt', 'LV Promos', 'HK', 'Consensus', 'IS detail', 'Sheet2', 'Sheet3', 'IndexInformation', 'ModPubIndex']\n",
      "Sheets to be checked: \n",
      "['Sheet2', 'Sheet1', 'Sheet3']\n",
      "The list of matches to be thrown into the database are: \n"
     ]
    }
   ],
   "source": [
    "filen=\"C:\\\\trial\\\\2018\\\\may\\\\2 MAY\\\\lvs\\\\LVS-Thomas Allen.xlsx\"\n",
    "print(filen)\n",
    "path_list=formating(filen)    \n",
    "print(\"The current ticker that is detected is \", path_list[3])\n",
    "ticker_input = input(\"Would you like to proceed with this ticker? [Y]//[N] \")\n",
    "if(ticker_input is \"Y\"):\n",
    "    ticker_name = path_list[3]\n",
    "else:\n",
    "    ticker_name = input(\"please enter the ticker code \")\n",
    "ticker_name = ticker_name.lower()\n",
    "a = corpus_list\n",
    "csv_file = ticker_name +\"_matches.csv\"\n",
    "a = list(map(lambda x: x.replace(\"C:\\\\Users\\\\admin\\\\thapovan\\\\Thapovan2\\\\Corpus\\\\\",''),a))\n",
    "if(csv_file in a):\n",
    "    print(\"The dictionary has already been built\")\n",
    "else:\n",
    "    ticker_list.append(ticker_name.lower())\n",
    "    \n",
    "    ticker_dictionary_build(ticker_name)\n",
    "    csv_file = ticker_name +\"_matches.csv\" \n",
    "ticker_dictionary = pd.read_csv(csv_file, error_bad_lines=False)\n",
    "val=function1(filen,path_list)\n",
    "if val==1:\n",
    "    print(\"FAULT\")\n",
    "elif val==2:\n",
    "    print(\"fault with sheet name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "len(ticker_dictionary['matches'][2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob(\"C:\\\\Users\\\\admin\\\\thapovan\\\\Thapovan2\\\\Corpus\\*csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = str(rohan).strip(\"][\").replace(\"'\",\"\").replace(\", \",\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Net Income,RevPar,Slots'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (ticker_dictionary['matches'][2]).strip(\"][\").replace(\"'\",\"\").replace(\", \",\",\")\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_stmt1 = F\"select distinct subsidiary_id from dbo.cc_actual_metrics_consolidated where \" \\\n",
    "                    F\"metric_name = 'Property, Plant & Equipment' and quarter = 'Q1' and ticker_code = 'AAP' and financial_year = 2017 and value like 1439.6200\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyodbc.Cursor at 0x21a59a48918>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " cursor.execute(select_stmt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=str(cursor.fetchone())\n",
    "#m = []\n",
    "#while b:\n",
    "#    m.append(str(b.subsidiary_name))\n",
    "#    b= cursor.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, )\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-8f88b56b286b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcorpus_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:\\\\Users\\\\admin\\\\thapovan\\\\Thapovan2\\\\Corpus\\\\\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "corpus_list.replace(\"C:\\\\Users\\\\admin\\\\thapovan\\\\Thapovan2\\\\Corpus\\\\\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = corpus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " a = list(map(lambda x: x.replace(\"C:\\\\Users\\\\admin\\\\thapovan\\\\Thapovan2\\\\Corpus\\\\\",''),a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Decimal('0.6206'), )\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "if(\"lvs_matches.csv\" in a):\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"rohan ---> Philip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rohan ', ' Philip']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.split(\"--->\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-304fa4ce4ebd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'100% Equities Strategy '"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Definition</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100% Mortgage</td>\n",
       "      <td>100% mortgage is amortgage loan in which the ...</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Term                                         Definition  \\\n",
       "2  100% Mortgage   100% mortgage is amortgage loan in which the ...   \n",
       "\n",
       "   word_count  \n",
       "2          41  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[[],'Term':'word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=d.append(data.loc[[2],'Term'], ignore_index =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Definition</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100% Mortgage</td>\n",
       "      <td>100% mortgage is amortgage loan in which the ...</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Term                                         Definition  \\\n",
       "0  100% Mortgage   100% mortgage is amortgage loan in which the ...   \n",
       "\n",
       "   word_count  \n",
       "0          41  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_stmt1 = F\"select metric_name from dbo.cc_actual_metrics_consolidated where \" \\\n",
    "                    F\"ticker_code = 'AAP' and (value like {valueo} or value like {value1} or value like {value3})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = -18.43\n",
    "valueo= \"'\"+str(value*100)+\"'\" #orginal with 100 multiplied\n",
    "value1 = \"'\"+str(int(value*100))+\".%\"+\"'\" # multiply by 100 and then integered\n",
    "value3 = \"'\"+str(-1*int(value*100))+\".%\"+\"'\" # multiply by 100 and integer and negate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'1066.%'\n"
     ]
    }
   ],
   "source": [
    "print(value3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "valueo = \"'\"+str(value)+\"'\" #orginal value\n",
    "value1 = \"'\"+str(round(value,2))+\"%\"+\"'\" # round upto 2\n",
    "value3 = \"'\"+str(-1*round(value,2))+\"%\"+\"'\" # round upto 2  and negate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= pd.DataFrame(columns=['A','B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a():\n",
    "    a = [1,2,3]\n",
    "    b= [4,5,6]\n",
    "    return(a,b)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "r,s = a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = \"rohan[56]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-897478779bd5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mr\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;34m\"han\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "r - \"han\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = r[r.find(\"[\")+1:r.find(\"]\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rohan[]'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.replace(r1,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "r =10     \n",
    "r3 =10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r=                10 \n",
      "r3=               10\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'r=':<15}{r:>5}\",\n",
    "      f\"\\n{'r3=':<15}{r3:>5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "students = [ ('jack', 34, 'Sydeny') ,\n",
    "('Riti', 30, 'Delhi' ) ,\n",
    "('Aadi', 16, 'New York') ]\n",
    "# Create a DataFrame object\n",
    "dfObj = pd.DataFrame(students, columns = ['Name' , 'Age', 'City']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObj['a'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = dfObj.index.values\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'pyodbc.Connection' object has no attribute 'ping'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-2db3c0b1e526>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcnxn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreconnect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattempt\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'pyodbc.Connection' object has no attribute 'ping'"
     ]
    }
   ],
   "source": [
    "cnxn.ping(reconnect = True, attempt =3, delay=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'a'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-8fce877f8ad6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdfObj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdfObj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mset_index\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   4176\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4177\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4178\u001b[1;33m                 \u001b[0mlevel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4179\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4180\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2927\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2657\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'a'"
     ]
    }
   ],
   "source": [
    "dfObj=dfObj.set_index('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =['1','2','3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jack</td>\n",
       "      <td>34</td>\n",
       "      <td>Sydeny</td>\n",
       "      <td>ab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Riti</td>\n",
       "      <td>30</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aadi</td>\n",
       "      <td>16</td>\n",
       "      <td>New York</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name  Age      City   a\n",
       "0  jack   34    Sydeny  ab\n",
       "1  Riti   30     Delhi   b\n",
       "2  Aadi   16  New York   c"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display((dfObj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tkinter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Could not find a version that satisfies the requirement tkinter (from versions: )\n",
      "No matching distribution found for tkinter\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install tkinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(a)):\n",
    "    a[i] =int(a[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "@safe_run\n",
    "def name():\n",
    "    print(\"name\")\n",
    "    print(name1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n"
     ]
    }
   ],
   "source": [
    "name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_run(func):\n",
    "\n",
    "    def func_wrapper(*args, **kwargs):\n",
    "\n",
    "        try:\n",
    "           return func(*args, **kwargs)\n",
    "\n",
    "        except Exception as e:\n",
    "            server = ast.literal_eval(con.get(\"Setting\",\"server\"))\n",
    "            database = ast.literal_eval(con.get(\"Setting\",\"database\"))\n",
    "            username = ast.literal_eval(con.get(\"Setting\",\"username\"))\n",
    "            password = ast.literal_eval(con.get(\"Setting\",\"password\"))\n",
    "            cnxn = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "            cursor = cnxn.cursor()\n",
    "            return None\n",
    "\n",
    "    return func_wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
