{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-51e6cb556b53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msimple_preprocess\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparsing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "from nltk import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "lem = WordNetLemmatizer()\n",
    "stem = PorterStemmer()\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "new_words = [\"using\", \"show\", \"result\", \"large\", \"also\", \"iv\", \"one\", \"two\", \"new\", \"previously\", \"shown\"]\n",
    "stop_words = stop_words.union(new_words)\n",
    "data1 = pd.read_csv(\"values1.csv\", error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\admin\\\\thapovan\\\\Thapovan2\\\\Corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Thapovan_data.csv\", error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>net calculation way providing cash discount pu...</td>\n",
       "      <td>['within day', 'discount', 'day', 'within', 'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>equity strategy investment strategy individual...</td>\n",
       "      <td>['equity', 'strategy', 'listed stock', 'equity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mortgage mortgage loan borrower receives loan ...</td>\n",
       "      <td>['loan', 'borrower', 'mortgage', 'loan borrowe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>form standard internal revenue service irs for...</td>\n",
       "      <td>['form', 'tax', 'taxpayer', 'whether', 'ascert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>form simplified version form individual income...</td>\n",
       "      <td>['form', 'certain requirement', 'individual mu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Corpus  \\\n",
       "0  net calculation way providing cash discount pu...   \n",
       "1  equity strategy investment strategy individual...   \n",
       "2  mortgage mortgage loan borrower receives loan ...   \n",
       "3  form standard internal revenue service irs for...   \n",
       "4  form simplified version form individual income...   \n",
       "\n",
       "                                             Keyword  \n",
       "0  ['within day', 'discount', 'day', 'within', 'a...  \n",
       "1  ['equity', 'strategy', 'listed stock', 'equity...  \n",
       "2  ['loan', 'borrower', 'mortgage', 'loan borrowe...  \n",
       "3  ['form', 'tax', 'taxpayer', 'whether', 'ascert...  \n",
       "4  ['form', 'certain requirement', 'individual mu...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_match_list(db,trial):\n",
    "    p_list = []\n",
    "    for i in range(0,len(db)):\n",
    "        metric = db['metric_name'][i]\n",
    "        text = re.sub('[^a-zA-Z]', ' ', metric)\n",
    "    \n",
    "        #Convert to lowercase\n",
    "        text = text.lower()\n",
    "    \n",
    "        #remove tags\n",
    "        text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
    "    \n",
    "        # remove special characters and digits\n",
    "        text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "        ##Convert to list from string\n",
    "        text = text.split()\n",
    "    \n",
    "        ##Stemming\n",
    "        ps=PorterStemmer()\n",
    "        #Lemmatisation\n",
    "        lem = WordNetLemmatizer()\n",
    "        text = [lem.lemmatize(word) for word in text if not word in  \n",
    "            stop_words] \n",
    "        text = \" \".join(text)\n",
    "        tex_check = text.split(\" \")\n",
    "        list=[]\n",
    "        for key in data1[\"Keyword\"]:\n",
    "            count = 0\n",
    "            for j in tex_check:\n",
    "                if(j in key):\n",
    "                    count = count+1\n",
    "            list.append((count/len(tex_check))*100)  \n",
    "        l = []\n",
    "        count1 = 0 \n",
    "        maxi = max(list)\n",
    "        for val in list:\n",
    "            if(val==maxi):\n",
    "                l.append(count1)\n",
    "            count1 = count1+1 \n",
    "        l2=[]\n",
    "        for j in l:\n",
    "            l2.append(data['Term'][j])\n",
    "        p_list.append(l2)      \n",
    "    db['possible'] = p_list\n",
    "    t_list = []\n",
    "    for i in range(0,len(trial)):\n",
    "        metric = trial['trial'][i]\n",
    "        text = re.sub('[^a-zA-Z]', ' ', metric)\n",
    "    \n",
    "        #Convert to lowercase\n",
    "        text = text.lower()\n",
    "    \n",
    "        #remove tags\n",
    "        text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
    "    \n",
    "        # remove special characters and digits\n",
    "        text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "        ##Convert to list from string\n",
    "        text = text.split()\n",
    "    \n",
    "        ##Stemming\n",
    "        ps=PorterStemmer()\n",
    "        #Lemmatisation\n",
    "        lem = WordNetLemmatizer()\n",
    "        text = [lem.lemmatize(word) for word in text if not word in  \n",
    "            stop_words] \n",
    "        text = \" \".join(text)\n",
    "        tex_check = text.split(\" \")\n",
    "        list=[]\n",
    "        for key in data1[\"Keyword\"]:\n",
    "            count = 0\n",
    "            for j in tex_check:\n",
    "                if(j in key):\n",
    "                    count = count+1\n",
    "            list.append((count/len(tex_check))*100)  \n",
    "        l = []\n",
    "        count1 = 0 \n",
    "        maxi = max(list)\n",
    "        for val in list:\n",
    "            if(val==maxi):\n",
    "                l.append(count1)\n",
    "            count1 = count1+1 \n",
    "        l2=[]\n",
    "        for j in l:\n",
    "            l2.append(data['Term'][j])\n",
    "        t_list.append(l2)    \n",
    "    trial['possible'] = t_list    \n",
    "    final_list = []\n",
    "    fill = []\n",
    "    for i in range(0,len(db)):\n",
    "        metric = db['possible'][i]\n",
    "        final = []\n",
    "        for j in range(0,len(trial)):\n",
    "            count = 0\n",
    "            for k in trial['possible'][j]:\n",
    "                if(k in metric):\n",
    "                    count = count+1\n",
    "            final.append((count/len(trial['possible'][j]))*100)\n",
    "            l3 =[]\n",
    "            for k in range(0,len(final)):\n",
    "                if(final[k]>0):\n",
    "                    l3.append(trial['trial'][k])\n",
    "        if(len(l3)==len(final)):\n",
    "            final_list.append(fill)\n",
    "        else:    \n",
    "            final_list.append(l3) \n",
    "    return(final_list)       \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric_name</th>\n",
       "      <th>possible</th>\n",
       "      <th>matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accounts Payable</td>\n",
       "      <td>[Accounts Payable (AP) , Accounts Payable Subs...</td>\n",
       "      <td>[FCF &amp; Balance Sheet Model, D&amp;A, FAS 123, Pari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accounts Receivable</td>\n",
       "      <td>[Accounts Receivable (AR) , Accounts Receivabl...</td>\n",
       "      <td>[FCF &amp; Balance Sheet Model, D&amp;A, FAS 123, Pari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adjusted EBITDA</td>\n",
       "      <td>[Adjusted Balance Method , Adjusted Basis , Ad...</td>\n",
       "      <td>[Free Cash Flow Model, D&amp;A, FAS 123, Gross Fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adjusted EBITDA Before Rent Expense</td>\n",
       "      <td>[Accrued Expense , Adjusted Earnings , Adjuste...</td>\n",
       "      <td>[FCF &amp; Balance Sheet Model, D&amp;A, FAS 123, Less...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adjusted EBITDA Margin (% of Total Revenues)</td>\n",
       "      <td>[EBITDA Margin ]</td>\n",
       "      <td>[D&amp;A, Parisian Macau, Venetian Macau, Other, T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    metric_name  \\\n",
       "0                              Accounts Payable   \n",
       "1                           Accounts Receivable   \n",
       "2                               Adjusted EBITDA   \n",
       "3           Adjusted EBITDA Before Rent Expense   \n",
       "4  Adjusted EBITDA Margin (% of Total Revenues)   \n",
       "\n",
       "                                            possible  \\\n",
       "0  [Accounts Payable (AP) , Accounts Payable Subs...   \n",
       "1  [Accounts Receivable (AR) , Accounts Receivabl...   \n",
       "2  [Adjusted Balance Method , Adjusted Basis , Ad...   \n",
       "3  [Accrued Expense , Adjusted Earnings , Adjuste...   \n",
       "4                                   [EBITDA Margin ]   \n",
       "\n",
       "                                             matches  \n",
       "0  [FCF & Balance Sheet Model, D&A, FAS 123, Pari...  \n",
       "1  [FCF & Balance Sheet Model, D&A, FAS 123, Pari...  \n",
       "2  [Free Cash Flow Model, D&A, FAS 123, Gross Fre...  \n",
       "3  [FCF & Balance Sheet Model, D&A, FAS 123, Less...  \n",
       "4  [D&A, Parisian Macau, Venetian Macau, Other, T...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = pd.read_csv(\"lvs_actual_metric.csv\", error_bad_lines=False)\n",
    "trial = pd.read_csv(\"test1.csv\", error_bad_lines=False)\n",
    "final_matches = return_match_list(db,trial)\n",
    "db['matches'] = final_matches\n",
    "db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
